{
 "metadata": {
  "name": "",
  "signature": "sha256:10df1233702a6aefd900c56e73bc359224511958323b012a2f4b199960139c14"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Getting Patent Details in Parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The usual imports, also importing the multiprocessing module. This comes with python."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd\n",
      "import re\n",
      "import html5lib\n",
      "import os\n",
      "from selenium.common.exceptions import NoSuchElementException    \n",
      "from selenium.webdriver.common.by import By\n",
      "from selenium.webdriver.support.ui import WebDriverWait\n",
      "from selenium.webdriver.support import expected_conditions as EC\n",
      "from selenium import webdriver\n",
      "from pyvirtualdisplay import Display\n",
      "import pyvirtualdisplay\n",
      "from selenium.webdriver.firefox.webdriver import FirefoxBinary\n",
      "from multiprocessing import Pool\n",
      "import csv\n",
      "from multiprocessing import cpu_count\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Importing the csvs and setting up the urls to scrape"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am setting up to run the first 270000. To run the rest set row 3 to: url = urls[270000:]. Set your own file location where you will grab the csv. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "All_Patent_Data = pd.read_csv('/Users/Alex/Documents/Patent Scraper.csv')\n",
      "urls = All_Patent_Data['url']\n",
      "url = urls[10000:20000]\n",
      "url"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "10000    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10001    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10002    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10003    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10004    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10005    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10006    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10007    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10008    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10009    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10010    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10011    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10012    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10013    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "10014    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "...\n",
        "19985    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19986    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19987    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19988    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19989    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19990    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19991    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19992    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19993    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19994    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19995    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19996    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19997    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19998    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "19999    http://pericles.ipaustralia.gov.au/ols/auspat/...\n",
        "Name: url, Length: 10000, dtype: object"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Defining the scrape function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are setting up the function to return Url, Title, Inventor, Agent, Company to the function. When we run the function in parallel later we will collect the results of each function and send them to a csv in one go."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Patent = {'Url':[],\n",
      "        'Title':[],\n",
      "          'Inventor':[],\n",
      "          'Agent':[],\n",
      "          'Company':[]}\n",
      "def get_patent_details(url):\n",
      "    Url=[]\n",
      "    Title=[]\n",
      "    Inventor=[]\n",
      "    Agent=[]\n",
      "    Company=[]\n",
      "    try:\n",
      "        binary = FirefoxBinary()\n",
      "        driver = webdriver.Firefox(None, binary)\n",
      "        driver.get(url)\n",
      "        WebDriverWait(driver, 1000).until(EC.visibility_of_element_located((By.CLASS_NAME, \"submit-button\")))\n",
      "        Accept_Xpath = '//input[@value=\"Accept\"]'\n",
      "        button = driver.find_element_by_xpath(Accept_Xpath)\n",
      "        button.click()\n",
      "        html_source = driver.page_source\n",
      "        soup = BeautifulSoup(html_source,'html.parser')\n",
      "        driver.quit()\n",
      "        Title.append(soup.find('td',class_='title',title=\"The Title of the Application\").findNext('td').contents[0].strip())\n",
      "        Agent.append(soup.find('td',class_='title',title=\"The name of the Applicant(s) legal agent\").findNext('td').contents[0].strip())\n",
      "        Inventor.append(soup.find('td',class_='title',title=\"The person(s) named on the Application as the Inventor\").findNext('td').contents[0].strip())\n",
      "        Company.append(soup.find('td',class_='title',title=\"The name of the person(s) or organisation(s) making Application for grant of patent\").findNext('td').contents[0].strip())\n",
      "        Url.append(url)\n",
      "    except:\n",
      "        Title.append(\"Search Failed\")\n",
      "        Agent.append(\"Search Failed\")\n",
      "        Inventor.append(\"Search Failed\")\n",
      "        Company.append(\"Search Failed\")\n",
      "        Url.append(url)\n",
      "    return Url, Title, Inventor, Agent, Company"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Running our function in Parallel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pool sets the number of workers, in this case i've set one worker for each cpu for 8 in total. you can also set any arbitrary number of workers with pool = Pool(40) if you wanted 40 workers. one worker per cpu seems to work well without slowing down my laptop but 2 per cpu is too many."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t0 = time.time()\n",
      "Url, Title, Inventor, Agent, Company = get_patent_details(url)\n",
      "if __name__ == \"__main__\":    \n",
      "    FILE_LINES = 10000\n",
      "    NUM_WORKERS = 4\n",
      "    pool = Pool(2)\n",
      "    pool.daemon = True\n",
      "    chunksize = FILE_LINES // NUM_WORKERS / 10\n",
      "    result_iter = pool.imap(get_patent_details, url,chunksize=chunksize)\n",
      "    with open(\"10000_to_19999 Patents.csv\", \"ab\") as f:\n",
      "        writeFile = csv.writer(f)\n",
      "        for result in result_iter:\n",
      "            writeFile.writerow(result)\n",
      "t1 = time.time()\n",
      "total = t1-t0\n",
      "total"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "42808.215153217316"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<multiprocessing.pool.IMapIterator at 0x10b7a52d0>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}